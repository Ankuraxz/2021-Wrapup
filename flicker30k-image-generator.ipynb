{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n<!--     for filename in filenames:\n        print(os.path.join(dirname, filename)) -->\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"#importing libraries   \nimport pandas as pd\nimport numpy as np\nimport cv2 \nimport os\nimport glob","metadata":{"execution":{"iopub.status.busy":"2023-09-29T22:14:04.106035Z","iopub.execute_input":"2023-09-29T22:14:04.106819Z","iopub.status.idle":"2023-09-29T22:14:04.666826Z","shell.execute_reply.started":"2023-09-29T22:14:04.106787Z","shell.execute_reply":"2023-09-29T22:14:04.665786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#importing Images\nimages_path=\"../input/flickr30k/Images/flickr30k_images/\"\nimages=glob.glob(images_path+\"*.jpg\")\nlen(images)\nimages[:5]\nimport matplotlib.pyplot as plt\nfor i in range(5):\n    plt.figure()\n    img=cv2.imread(images[i])\n    img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n    plt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T22:14:04.668911Z","iopub.execute_input":"2023-09-29T22:14:04.669625Z","iopub.status.idle":"2023-09-29T22:14:09.184986Z","shell.execute_reply.started":"2023-09-29T22:14:04.669587Z","shell.execute_reply":"2023-09-29T22:14:09.183363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#captions\ncaption_path = '../input/flickr30k/captions.txt'\ncaptions = open(caption_path, 'rb').read().decode('utf-8').split('\\n')\nlen(captions)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T22:14:09.186675Z","iopub.execute_input":"2023-09-29T22:14:09.188684Z","iopub.status.idle":"2023-09-29T22:14:09.413442Z","shell.execute_reply.started":"2023-09-29T22:14:09.188638Z","shell.execute_reply":"2023-09-29T22:14:09.412467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"captions[13]","metadata":{"execution":{"iopub.status.busy":"2023-09-29T22:14:09.415847Z","iopub.execute_input":"2023-09-29T22:14:09.417012Z","iopub.status.idle":"2023-09-29T22:14:09.423812Z","shell.execute_reply.started":"2023-09-29T22:14:09.416977Z","shell.execute_reply":"2023-09-29T22:14:09.422981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(captions[:5])\nprint(len(captions[:5]))","metadata":{"execution":{"iopub.status.busy":"2023-09-29T22:14:09.426011Z","iopub.execute_input":"2023-09-29T22:14:09.427332Z","iopub.status.idle":"2023-09-29T22:14:09.434745Z","shell.execute_reply.started":"2023-09-29T22:14:09.427300Z","shell.execute_reply":"2023-09-29T22:14:09.433826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# seperate Image & Caption\nprint(f'{captions[:5][1]}')\nimg,caption = captions[:5][1].split(\",\")\nprint(img)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T22:14:09.435872Z","iopub.execute_input":"2023-09-29T22:14:09.436557Z","iopub.status.idle":"2023-09-29T22:14:09.445015Z","shell.execute_reply.started":"2023-09-29T22:14:09.436525Z","shell.execute_reply":"2023-09-29T22:14:09.443834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pathx = str(images_path+img)\n# print(pathx)\nimg = cv2.imread(pathx)\nimg=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\nplt.imshow(img)\nprint(caption)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T22:14:09.446626Z","iopub.execute_input":"2023-09-29T22:14:09.447303Z","iopub.status.idle":"2023-09-29T22:14:09.774867Z","shell.execute_reply.started":"2023-09-29T22:14:09.447272Z","shell.execute_reply":"2023-09-29T22:14:09.774084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# seperate Image & Caption\nprint(f'{captions[13]}')\nimg,caption = captions[13].split(\",\")\nprint(img)\n\npathx = str(images_path+img)\n# print(pathx)\nimg = cv2.imread(pathx)\nimg=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\nplt.imshow(img)\nprint(caption)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T22:14:09.776206Z","iopub.execute_input":"2023-09-29T22:14:09.776702Z","iopub.status.idle":"2023-09-29T22:14:10.092554Z","shell.execute_reply.started":"2023-09-29T22:14:09.776668Z","shell.execute_reply":"2023-09-29T22:14:10.091756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# seperate Image & Caption\nprint(f'{captions[131]}')\nimg,caption = captions[131].split(\",\")\nprint(img)\n\npathx = str(images_path+img)\n# print(pathx)\nimg = cv2.imread(pathx)\nimg=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\nplt.imshow(img)\nprint(caption)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T22:14:10.093980Z","iopub.execute_input":"2023-09-29T22:14:10.094595Z","iopub.status.idle":"2023-09-29T22:14:10.477548Z","shell.execute_reply.started":"2023-09-29T22:14:10.094563Z","shell.execute_reply":"2023-09-29T22:14:10.476739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# seperate Image & Caption\nprint(f'{captions[1310]}')\nimg,caption = captions[1310].split(\",\")\nprint(img)\n\npathx = str(images_path+img)\n# print(pathx)\nimg = cv2.imread(pathx)\nimg=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\nplt.imshow(img)\nprint(caption)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T22:14:10.480562Z","iopub.execute_input":"2023-09-29T22:14:10.481486Z","iopub.status.idle":"2023-09-29T22:14:10.798721Z","shell.execute_reply.started":"2023-09-29T22:14:10.481451Z","shell.execute_reply":"2023-09-29T22:14:10.797943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os # Handeling the file\nimport pickle #primarily used in serializing and deserializing a Python object structure\nimport pandas as pd\nimport numpy as np\nfrom tqdm.notebook import tqdm #used for creating Progress Meters or Progress Bars\n\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array \nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences # Even out the whole text representaion of features for the remaining length.\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.utils import to_categorical,plot_model\nfrom tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout,add","metadata":{"execution":{"iopub.status.busy":"2023-09-29T22:14:10.799945Z","iopub.execute_input":"2023-09-29T22:14:10.800788Z","iopub.status.idle":"2023-09-29T22:14:19.552518Z","shell.execute_reply.started":"2023-09-29T22:14:10.800751Z","shell.execute_reply":"2023-09-29T22:14:19.551245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.translate.bleu_score import corpus_bleu # Bleu score\n\nimport cv2\n\nimport pdb #python debugger\n\nimport matplotlib.pyplot as plt\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2023-09-29T22:14:19.553841Z","iopub.execute_input":"2023-09-29T22:14:19.554475Z","iopub.status.idle":"2023-09-29T22:14:20.564570Z","shell.execute_reply.started":"2023-09-29T22:14:19.554440Z","shell.execute_reply":"2023-09-29T22:14:20.563416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set directories\nBASE_DIR='../input/flickr30k'\nDATA_DIR='../input/flickr30k/Images'\n","metadata":{"execution":{"iopub.status.busy":"2023-09-29T22:14:20.565967Z","iopub.execute_input":"2023-09-29T22:14:20.566279Z","iopub.status.idle":"2023-09-29T22:14:20.570734Z","shell.execute_reply.started":"2023-09-29T22:14:20.566246Z","shell.execute_reply":"2023-09-29T22:14:20.569809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Libs","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import load_img, img_to_array \nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences # Even out the whole text representaion of features for the remaining length.\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.utils import to_categorical,plot_model\nfrom tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout,add\n\nfrom nltk.translate.bleu_score import corpus_bleu # Bleu score\n","metadata":{"execution":{"iopub.status.busy":"2023-09-29T22:14:20.572043Z","iopub.execute_input":"2023-09-29T22:14:20.572587Z","iopub.status.idle":"2023-09-29T22:14:20.583507Z","shell.execute_reply.started":"2023-09-29T22:14:20.572556Z","shell.execute_reply":"2023-09-29T22:14:20.582500Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Image Data","metadata":{}},{"cell_type":"code","source":"import glob\npath=glob.glob('../input/flickr30k/Images/*.jpg')\nprint(len(path))","metadata":{"execution":{"iopub.status.busy":"2023-09-29T22:14:20.584748Z","iopub.execute_input":"2023-09-29T22:14:20.585285Z","iopub.status.idle":"2023-09-29T22:14:22.483872Z","shell.execute_reply.started":"2023-09-29T22:14:20.585255Z","shell.execute_reply":"2023-09-29T22:14:22.482870Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model 1 - RESNET50","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\nresnet_model=ResNet50(weights='imagenet')\n#re-structure the model by removing last 2 layers\nresnet_model.layers.pop()\nresnet_model=Model(inputs=resnet_model.inputs, outputs=resnet_model.layers[-2].output) ##Dropping last 2 layers\n     ","metadata":{"execution":{"iopub.status.busy":"2023-09-29T22:16:01.682509Z","iopub.execute_input":"2023-09-29T22:16:01.682849Z","iopub.status.idle":"2023-09-29T22:16:03.487580Z","shell.execute_reply.started":"2023-09-29T22:16:01.682820Z","shell.execute_reply":"2023-09-29T22:16:03.486596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(resnet_model.summary())","metadata":{"execution":{"iopub.status.busy":"2023-09-29T22:16:08.261327Z","iopub.execute_input":"2023-09-29T22:16:08.261666Z","iopub.status.idle":"2023-09-29T22:16:08.564501Z","shell.execute_reply.started":"2023-09-29T22:16:08.261632Z","shell.execute_reply":"2023-09-29T22:16:08.563714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### EXTRACT FEATURES WITH RESNET50","metadata":{}},{"cell_type":"code","source":"features={}\n#count=0\nfor img_name in tqdm(path):\n #load the images from Images folder\n  img_file=cv2.imread(img_name)\n  #resize data for model \n  img_file=cv2.resize(img_file,(224,224))\n  #convert the image pixel to a numpy array\n  X=image.img_to_array(img_file)\n  #Reshape data for preprocess\n  X=X.reshape((1,X.shape[0],X.shape[1],X.shape[2]))\n    \n  X=preprocess_input(X)\n  #get features\n  feature=resnet_model.predict(X,verbose=0).reshape(2048,)\n  #Get image ID\n  image_id=((os.path.basename(img_name)).split('.')[0])\n  \n  #Store features\n  features[image_id]=feature","metadata":{"execution":{"iopub.status.busy":"2023-09-29T22:20:16.961724Z","iopub.execute_input":"2023-09-29T22:20:16.962087Z","iopub.status.idle":"2023-09-29T23:04:49.823424Z","shell.execute_reply.started":"2023-09-29T22:20:16.962058Z","shell.execute_reply":"2023-09-29T23:04:49.822391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"WORKING_DIR = '/kaggle/working'\n#Store featues in pickle\npickle.dump(features,open(os.path.join(WORKING_DIR,'features_resnet50.pk'),'wb'))","metadata":{"execution":{"iopub.status.busy":"2023-09-29T23:04:49.825326Z","iopub.execute_input":"2023-09-29T23:04:49.825580Z","iopub.status.idle":"2023-09-29T23:04:50.738561Z","shell.execute_reply.started":"2023-09-29T23:04:49.825556Z","shell.execute_reply":"2023-09-29T23:04:50.737573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Caption","metadata":{}},{"cell_type":"code","source":"def Cleanup(mapping):\n  import re\n  for key, captions in mapping.items():\n    for i in range(len(captions)):\n      #take one cations at a time\n      caption=captions[i]\n      #convert to lowercase\n      caption=caption.lower()\n      #deleate digits,special chars\n      caption=caption.replace('[^A-Za-z]', '')\n      #delete addinional spaces\n      caption=caption.replace('\\s+', ' ')\n      #Remove punctuations\n      caption = re.sub(r'[^\\w\\s]', '', caption)\n      #add start and end tags to the cation\n      caption='startseq '+ ' '.join([word for word in caption.split() if len(word)>1]) +' endseq'\n      captions[i]=caption\n  return ","metadata":{"execution":{"iopub.status.busy":"2023-09-29T23:48:50.294104Z","iopub.execute_input":"2023-09-29T23:48:50.294458Z","iopub.status.idle":"2023-09-29T23:48:50.301038Z","shell.execute_reply.started":"2023-09-29T23:48:50.294430Z","shell.execute_reply":"2023-09-29T23:48:50.300014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nwith open(os.path.join(BASE_DIR,'captions.txt'),'rb') as f:\n  next(f) # To remove 1st line \"Image, captions\"\n  Cap_doc=f.read().decode('utf-8').split('\\n')\nCap_doc[:10]\nwith open(os.path.join(BASE_DIR,'captions.txt'),'rb') as f:\n  next(f) # To remove 1st line \"Image, captions\"\n  Cap_doc=f.read().decode('utf-8').split('\\n')\nCap_doc[:10]","metadata":{"execution":{"iopub.status.busy":"2023-09-29T23:46:41.373597Z","iopub.execute_input":"2023-09-29T23:46:41.374049Z","iopub.status.idle":"2023-09-29T23:46:41.681932Z","shell.execute_reply.started":"2023-09-29T23:46:41.374015Z","shell.execute_reply":"2023-09-29T23:46:41.680957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mapping={}\n\nfor line in tqdm(Cap_doc):\n  #pdb.set_trace()\n  #split line by whit space\n  tokens=line.split(',')\n  if len(line)<1:\n    continue\n  # Take the 1st token as the image id and the rest as the description\n  image_id,image_desc=tokens[0],tokens[1:]\n  # Remove filename from image id\n  image_id=(image_id.split('.')[0])\n  #onvert description tokens back to string\n  image_desc=''.join(image_desc)\n  #print(image_desc)\n  #create list if needed\n  if image_id not in mapping:\n    mapping[image_id]=list()\n    #mapping[image_id]=[]\n  #store description\n  mapping[image_id].append(image_desc) ","metadata":{"execution":{"iopub.status.busy":"2023-09-29T23:46:55.843469Z","iopub.execute_input":"2023-09-29T23:46:55.843821Z","iopub.status.idle":"2023-09-29T23:46:56.107586Z","shell.execute_reply.started":"2023-09-29T23:46:55.843791Z","shell.execute_reply":"2023-09-29T23:46:56.106637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Cleanup(mapping)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T23:49:09.644771Z","iopub.execute_input":"2023-09-29T23:49:09.645543Z","iopub.status.idle":"2023-09-29T23:49:10.398537Z","shell.execute_reply.started":"2023-09-29T23:49:09.645509Z","shell.execute_reply":"2023-09-29T23:49:10.397584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mapping['1000268201']","metadata":{"execution":{"iopub.status.busy":"2023-09-29T23:50:44.967138Z","iopub.execute_input":"2023-09-29T23:50:44.967483Z","iopub.status.idle":"2023-09-29T23:50:44.973214Z","shell.execute_reply.started":"2023-09-29T23:50:44.967455Z","shell.execute_reply":"2023-09-29T23:50:44.972312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pickle.dump(mapping,open(os.path.join(WORKING_DIR,'Mapping.txt'),'wb'))","metadata":{"execution":{"iopub.status.busy":"2023-09-29T23:50:59.542858Z","iopub.execute_input":"2023-09-29T23:50:59.543238Z","iopub.status.idle":"2023-09-29T23:50:59.610049Z","shell.execute_reply.started":"2023-09-29T23:50:59.543210Z","shell.execute_reply":"2023-09-29T23:50:59.609067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LOAD IMAGE FEATURE & CAPTION","metadata":{}},{"cell_type":"code","source":"with open(os.path.join(WORKING_DIR,'features_resnet50.pk'),'rb') as f:\n  Img_features=pickle.load(f)\nlen(Img_features)\n     ","metadata":{"execution":{"iopub.status.busy":"2023-09-29T23:51:39.587180Z","iopub.execute_input":"2023-09-29T23:51:39.587538Z","iopub.status.idle":"2023-09-29T23:51:39.933530Z","shell.execute_reply.started":"2023-09-29T23:51:39.587509Z","shell.execute_reply":"2023-09-29T23:51:39.932532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(os.path.join(WORKING_DIR,'Mapping.txt'),'rb') as f:\n  Mapping=pickle.load(f)\nlen(Mapping)\n     ","metadata":{"execution":{"iopub.status.busy":"2023-09-29T23:52:12.153040Z","iopub.execute_input":"2023-09-29T23:52:12.153392Z","iopub.status.idle":"2023-09-29T23:52:12.215930Z","shell.execute_reply.started":"2023-09-29T23:52:12.153364Z","shell.execute_reply":"2023-09-29T23:52:12.214468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nall_captions=[]\nfor key in Mapping:\n  for caption in Mapping[key]:\n    all_captions.append(caption)\nall_captions[:10]","metadata":{"execution":{"iopub.status.busy":"2023-09-29T23:52:19.754940Z","iopub.execute_input":"2023-09-29T23:52:19.756083Z","iopub.status.idle":"2023-09-29T23:52:19.796503Z","shell.execute_reply.started":"2023-09-29T23:52:19.756049Z","shell.execute_reply":"2023-09-29T23:52:19.795427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_length_cap=max(len(caption.split())for caption in all_captions)\nmax_length_cap\n     ","metadata":{"execution":{"iopub.status.busy":"2023-09-29T23:52:33.029094Z","iopub.execute_input":"2023-09-29T23:52:33.030105Z","iopub.status.idle":"2023-09-29T23:52:33.145919Z","shell.execute_reply.started":"2023-09-29T23:52:33.030062Z","shell.execute_reply":"2023-09-29T23:52:33.144862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# tokenize the text \ntokenizer=Tokenizer()\ntokenizer.fit_on_texts(all_captions)\nvocab_dict=tokenizer.word_index\nvocab_size=len(vocab_dict)+1 # total number of unique word\nvocab_size","metadata":{"execution":{"iopub.status.busy":"2023-09-29T23:52:41.701173Z","iopub.execute_input":"2023-09-29T23:52:41.701507Z","iopub.status.idle":"2023-09-29T23:52:43.887317Z","shell.execute_reply.started":"2023-09-29T23:52:41.701481Z","shell.execute_reply":"2023-09-29T23:52:43.886346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Train test split\nimage_ids=list(Mapping.keys())\nsplit=int(len(image_ids)*0.9)\ntrain_id=image_ids[:split]\nprint(len(train_id))\n#Train_id chunk \ntrain_id_1=train_id[:2500]\ntrain_id_2=train_id[2500:5000]\ntrain_id_3=train_id[5000:]\n\ntest_id=image_ids[split:]\nprint(len(train_id_1),len(train_id_2),len(train_id_3))","metadata":{"execution":{"iopub.status.busy":"2023-09-29T23:52:56.617968Z","iopub.execute_input":"2023-09-29T23:52:56.618324Z","iopub.status.idle":"2023-09-29T23:52:56.626130Z","shell.execute_reply.started":"2023-09-29T23:52:56.618295Z","shell.execute_reply":"2023-09-29T23:52:56.625072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## DATAGEN","metadata":{}},{"cell_type":"code","source":"def data_generator(data_keys,features,mapping,tokenizer,max_length,vocab_size,batch_size):\n  X1,X2,y=[],[],[]\n  n=0\n  while 1:\n    for key in data_keys:\n      #print(key)\n      n+=1\n      captions=mapping[key]\n      #print(captions)\n      #process each captions\n      for caption in captions:\n        #encode the sequences\n        seq=tokenizer.texts_to_sequences([caption])[0]\n        #print(seq)\n        #spli sequence into X,y pairs\n        for i in range(1,len(seq)):\n          #print(seq[i])\n          #Split into input and output pairs\n          in_seq,out_seq=seq[:i],seq[i]\n          #print(in_seq,out_seq)\n          #pad input seq\n          in_seq=pad_sequences([in_seq],maxlen=max_length)[0]\n          #encode output seq\n          out_seq=to_categorical([out_seq],num_classes=vocab_size)[0]\n          #print(in_seq)\n          #print(out_seq)\n          #store the seq\n          X1.append(features[key])\n          X2.append(in_seq)\n          y.append(out_seq)\n          #print(len(X1),len(X2),len(y))\n          #print('X1:',X1)\n          #print('X2:',X2)\n          #print('y:',y)\n      if n==batch_size:\n        X1=np.array(X1)\n        X2=np.array(X2)\n        y=np.array(y)\n        #print(X1.shape,X2.shape,y.shape)\n        yield [X1,X2],y\n        X1,X2,y=[],[],[]\n        n=0\n     ","metadata":{"execution":{"iopub.status.busy":"2023-09-29T23:53:09.850004Z","iopub.execute_input":"2023-09-29T23:53:09.850731Z","iopub.status.idle":"2023-09-29T23:53:09.859011Z","shell.execute_reply.started":"2023-09-29T23:53:09.850695Z","shell.execute_reply":"2023-09-29T23:53:09.858049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#Encoder model\n#image Feature layers\ninputs1=Input(shape=(4096,))\nFeatures1=Dropout(0.4)(inputs1)\nFeatures2=Dense(256,activation='relu')(Features1)\n#Text features layers\ninputs2=Input(shape=(max_length_cap,))\nseq1=Embedding(vocab_size,256,mask_zero=True)(inputs2)\nseq2=Dropout(0.4)(seq1)\nseq3=LSTM(256)(seq2)\n\n#Decoder Model\ndecoder1=add([Features2,seq3])\ndecoder2=Dense(256,activation='relu')(decoder1)\noutputs=Dense(vocab_size,activation='softmax')(decoder2)\n\nmodel=Model(inputs=[inputs1,inputs2],outputs=outputs)\nmodel.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n\n#plot the model\nplot_model(model,show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T23:53:29.415560Z","iopub.execute_input":"2023-09-29T23:53:29.415935Z","iopub.status.idle":"2023-09-29T23:53:31.131875Z","shell.execute_reply.started":"2023-09-29T23:53:29.415895Z","shell.execute_reply":"2023-09-29T23:53:31.130922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## V1 of model","metadata":{}},{"cell_type":"code","source":"\n## Train model for total 55 epoch\nepochs=15\nbatch_size=64\nsteps=(len(train_id)//batch_size)\nfor i in tqdm(range(epochs)):\n  print('Epoch: ',i)\n  generator=data_generator(train_id,Img_features,Mapping,tokenizer,max_length_cap,vocab_size,batch_size)\n  model.fit(generator,epochs=1,steps_per_epoch=steps,shuffle=True,verbose=1)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T23:56:33.434102Z","iopub.execute_input":"2023-09-29T23:56:33.434455Z","iopub.status.idle":"2023-09-29T23:56:33.671086Z","shell.execute_reply.started":"2023-09-29T23:56:33.434425Z","shell.execute_reply":"2023-09-29T23:56:33.669835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_model.save(WORKING_DIR+'/best_model3.h5')","metadata":{},"execution_count":null,"outputs":[]}]}